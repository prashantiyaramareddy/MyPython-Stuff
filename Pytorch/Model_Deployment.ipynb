{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMVEr00mVyyeXT7TpzyrQUU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prashantiyaramareddy/MyPython-Stuff/blob/master/Pytorch/Model_Deployment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Model Deployment\n",
        "\n",
        "Machine learning model deployment is the act of making your machine learning model(s) available to someone or something else\n"
      ],
      "metadata": {
        "id": "tF3sYNKd8u5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Get setup"
      ],
      "metadata": {
        "id": "p9U9UT5aYuM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 1. Getting Data\n",
        "\n",
        "# For this notebook to run with updated API's, we need torch 1.12+ and torchvision 0.13+\n",
        "\n",
        "try:\n",
        "  import torch\n",
        "  import torchvision\n",
        "  assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
        "  assert int(torchvision.__version__.split(\".\")[0]) >= 13, \"torch version should be 0.13+\"\n",
        "  print(f\"torch version: {torch.__version__}\")\n",
        "  print(f\"torchvision version: {torchvision.__version__}\")\n",
        "except:\n",
        "  print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
        "  !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "  import torch\n",
        "  import torchvision\n",
        "  print(f\"torch version: {torch.__version__}\")\n",
        "  print(f\"torchvision version: {torchvision.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9sDVyIfYzq_",
        "outputId": "4b3e701c-2622-4b16-8495-7f9903feb582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] torch/torchvision versions not as required, installing nightly versions.\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting torch\n",
            "  Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.5.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m698.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvshmem-cu12\n",
            "    Found existing installation: nvidia-nvshmem-cu12 3.4.5\n",
            "    Uninstalling nvidia-nvshmem-cu12-3.4.5:\n",
            "      Successfully uninstalled nvidia-nvshmem-cu12-3.4.5\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo, install it if it does not work\n",
        "try:\n",
        "  from torchinfo import summary\n",
        "except:\n",
        "  print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "  !pip install -q torchinfo\n",
        "  from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it works\n",
        "try:\n",
        "  from going_modular.going_modular import data_setup, engine\n",
        "  from helper_functions import download_data, set_seeds, plot_loss_curves\n",
        "except:\n",
        "  # Get the going_modular scripts\n",
        "  print(\"[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub\")\n",
        "  !rm -rf pytorch-deep-learning\n",
        "  !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "  !mv pytorch-deep-learning/going_modular .\n",
        "  !mv pytorch-deep-learning/helper_functions.py .\n",
        "  !rm -rf pytorch-deep_learning\n",
        "  from going_modular.going_modular import data_setup, engine\n",
        "  from helper_functions import download_data, set_seeds, plot_loss_curves"
      ],
      "metadata": {
        "id": "uXFULnOoa1TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "yq6HAZd3iGUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Getting Data\n",
        "\n",
        "The dataset we are going to use for deploying a FoodVision Mini model is ...\n",
        "\n",
        "Pizza, steak, sushi 20% dataset (pizza, steak, sushi classes from Food101, random 20% of samples)\n"
      ],
      "metadata": {
        "id": "6nfp73J8iRhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pizza, steak, sushi images from Github\n",
        "data_20_percent_path = download_data(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\",destination=\"pizza_steak_sushi_20_percent\")\n",
        "\n",
        "data_20_percent_path"
      ],
      "metadata": {
        "id": "zjwXZryziqFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up training and test paths\n",
        "train_dir = data_20_percent_path / \"train\"\n",
        "test_dir = data_20_percent_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "neAY9sT6j5H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. FoodVision Mini model deployment experiment outline\n",
        "\n",
        "**FoodVision Mini ideal use case: * A model that performs well and fast\n",
        "\n",
        "* Performs well: 95% + accuracy\n",
        "* Fast: as close to real-time (or faster) as possible (30FPS+ or 30ms latency)\n",
        "\n",
        " * latency = time for prediction to take place\n",
        "\n",
        " To try and achieve these goals, we are going to build two model experiments\n",
        " 1. EffNetB2 feature extractor\n",
        " 2. ViT feature extractor"
      ],
      "metadata": {
        "id": "BVXs_fQ4j-1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Creating an EffNetB2 feature extractor\n",
        "\n",
        "Feature extractor = a term for a transfer learning modelthat has its base layers frozen and output layers customized to a certain problem\n",
        "\n",
        "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.efficientnet_b2.html#torchvision.models.EfficientNet_B2_Weights\n"
      ],
      "metadata": {
        "id": "tTekQ2Fuk9yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "# 1. Setup pretrained EffNetB2 weights\n",
        "effnetb2_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "# 2. Get the transforms\n",
        "effnetb2_transforms = effnetb2_weights.transforms()\n",
        "\n",
        "# 3. Setup pretrained model instance\n",
        "effnetb2 = torchvision.models.efficientnet_b2(weights=effnetb2_weights).to(device)\n",
        "\n",
        "# 4. Freeze base layers in the model ( this will stop all layers from training)\n",
        "for param in effnetb2.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "effnetb2"
      ],
      "metadata": {
        "id": "jj-XsUAfmR0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Update the classifier head\n",
        "set_seeds()\n",
        "effnetb2.classifier"
      ],
      "metadata": {
        "id": "Iy-b09vrk5Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cCvhIH5dlL_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(effnetb2, input_size=(1,3,224,224), col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"], col_width=20, row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "id": "vWTGceoTnhCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2.classifier"
      ],
      "metadata": {
        "id": "C0qJUcGmnoRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seeds for reproducibility\n",
        "set_seeds()\n",
        "effnetb2.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.3, inplace=True),\n",
        "    nn.Linear(in_features=1408, out_features=3, bias=True)\n",
        ").to(device)\n",
        "\n",
        "from torchinfo import summary\n",
        "summary(effnetb2, input_size=(1,3,224,224), col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"], col_width=20, row_settings=[\"var_names\"])\n",
        "#"
      ],
      "metadata": {
        "id": "h2xsoxhunr8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 3.1 Creating a function to make an EffNet B2 feature extractor\n",
        "def create_effnetb2_feature_extractor(num_classes=3, seed=42):\n",
        "  # 1, 2, 3 Create EffNetB2 pretrained weights, transforms and model\n",
        "  weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "  transforms = weights.transforms()\n",
        "  model = torchvision.models.efficientnet_b2(weights=weights)\n",
        "\n",
        "  # 4. Freeze all layers in the base\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "  # 5. Change classifier head with random seed for reproducibility\n",
        "  torch.manual_seed(seed)\n",
        "  model.classifier = nn.Sequential(\n",
        "      nn.Dropout(p=0.3, inplace=True),\n",
        "      nn.Linear(in_features=1408, out_features=num_classes)\n",
        "  )\n",
        "\n",
        "  return model, transforms"
      ],
      "metadata": {
        "id": "ZXTvXFDop6AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_model, effnetb2_transforms = create_effnetb2_feature_extractor(num_classes=3, seed=42)\n",
        "effnetb2_model"
      ],
      "metadata": {
        "id": "Fit1OEJjq-Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "# Print EffNetB2 model summary (uncomment for full output)\n",
        "summary(effnetb2,\n",
        "        input_size=(1,3,224,224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])\n",
        "#"
      ],
      "metadata": {
        "id": "wkpb4ryjrK6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2, effnetb2.transforms = create_effnetb2_feature_extractor(num_classes=3, seed=42)"
      ],
      "metadata": {
        "id": "oN6EAV4PsdkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2.transforms"
      ],
      "metadata": {
        "id": "xvNjtj1OsiBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 3.2 Setup DataLoaders\n",
        "from going_modular.going_modular import data_setup\n",
        "\n",
        "train_dataloader_effnetb2, test_dataloader_effnetb2, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                                                 test_dir = test_dir,\n",
        "                                                                                                 transform = effnetb2_transforms,\n",
        "                                                                                                 batch_size=32)\n",
        "len(train_dataloader_effnetb2), len(test_dataloader_effnetb2), class_names"
      ],
      "metadata": {
        "id": "AfB6l4NtswIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Training EffNetB2 feature extractor\n"
      ],
      "metadata": {
        "id": "CwlHvQw7K7zK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import engine\n",
        "\n",
        "# Setup hyperparameters\n",
        "NUM_EPOCHS = 50\n",
        "LEARNING_RATE = 0.001\n",
        "WEIGHT_DECAY = 0.01\n",
        "\n",
        "# Create loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(effnetb2_model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Training function (engine.py)\n",
        "set_seeds()\n",
        "effnetb2_results = engine.train(model=effnetb2_model,\n",
        "                                train_dataloader=train_dataloader_effnetb2,\n",
        "                                test_dataloader=test_dataloader_effnetb2,\n",
        "                                optimizer=optimizer,\n",
        "                                loss_fn=loss_fn,\n",
        "                                epochs=NUM_EPOCHS,\n",
        "                                device=device)"
      ],
      "metadata": {
        "id": "djR5G7iOLC45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 Inspecting Loss Curves"
      ],
      "metadata": {
        "id": "RaqbQywjcBSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import plot_loss_curves\n",
        "\n",
        "plot_loss_curves(effnetb2_results)"
      ],
      "metadata": {
        "id": "nPhkSBGhcFD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5 Saving EffNetB2 feature extractor"
      ],
      "metadata": {
        "id": "NV-cJ7sscSry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import utils\n",
        "\n",
        "utils.save_model(model=effnetb2_model,\n",
        "                 target_dir=\"models\",\n",
        "                 model_name=\"effnetb2_feature_extractor_20_percent.pth\")"
      ],
      "metadata": {
        "id": "0SbssB-CeR2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.6 Inspecting the size of the EffNetB2 feature extractor"
      ],
      "metadata": {
        "id": "qmky85ppnvFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Get the model size in bytes then convert to megabytes\n",
        "model_path = Path(\"models/effnetb2_feature_extractor_20_percent.pth\")\n",
        "Pretrained_model_size_bytes = model_path.stat().st_size\n",
        "\n",
        "print(f\"Model size: {Pretrained_model_size_bytes} bytes\")\n",
        "print(f\"Model size: {Pretrained_model_size_bytes / (1024 * 1024)} megabytes\")"
      ],
      "metadata": {
        "id": "8_ypcnWpn3fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.7. Collecting EffNetB2 feature extractor stats\n",
        "\n",
        "We have got a few statistics about the EffNetB2 model such as test loss, test accuracy and model size, how about we collect all of them in a dictionary so we can compare them to the upcoming ViT feature extractor\n",
        "\n"
      ],
      "metadata": {
        "id": "9Yil8Y5solRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count number of parameters in EffnetB2\n",
        "effnetb2_total_params = sum([param.numel() for param in effnetb2_model.parameters()])\n",
        "effnetb2_total_params"
      ],
      "metadata": {
        "id": "jzCjKVJmpSIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary with EffNetB2 statistics\n",
        "effnetb2_stats = {\n",
        "    \"test_loss\": effnetb2_results['test_loss'][-1],\n",
        "    \"test_acc\": effnetb2_results['test_acc'][-1],\n",
        "    \"model_size (MB)\": Pretrained_model_size_bytes / (1024 * 1024),\n",
        "    \"num_params\": effnetb2_total_params}\n",
        "\n",
        "effnetb2_stats"
      ],
      "metadata": {
        "id": "iQdkrYvwqZsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Creating a ViT feature extractor"
      ],
      "metadata": {
        "id": "JNp2N6lZquVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out ViT heads layer\n",
        "vit = torchvision.models.vit_b_16(weights=None)\n",
        "vit.heads"
      ],
      "metadata": {
        "id": "9FLzxkz_rM94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vit_feature_extractor(num_classes=3, seed=42):\n",
        "  # 1. Create ViT pretrained weights, transforms and model\n",
        "  weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
        "  transforms = weights.transforms()\n",
        "  model = torchvision.models.vit_b_16(weights=weights)\n",
        "\n",
        "  # Freeze all layers in the model\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "  # Change classifier head to suit our needs ( this will be trainable)\n",
        "  torch.manual_seed(seed)\n",
        "  model.heads = nn.Sequential(nn.Linear(in_features=768, out_features=num_classes))\n",
        "\n",
        "  return model, transforms"
      ],
      "metadata": {
        "id": "OCXET6htrd_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ViT model and transforms\n",
        "vit_model, vit_transforms = create_vit_feature_extractor(num_classes=3, seed=42)\n",
        "vit_model"
      ],
      "metadata": {
        "id": "jHjwbYftsQMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the summary of ViT feature extractor model\n",
        "from torchinfo import summary\n",
        "\n",
        "summary(vit_model,input_size=(1,3,224,224), col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"], col_width=20, row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "id": "82N9DFwbsgaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Create data loaders for ViT\n"
      ],
      "metadata": {
        "id": "czhuSx_8tDnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import data_setup\n",
        "\n",
        "train_dataloader_vit, test_dataloader_vit, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                                       test_dir = test_dir,\n",
        "                                                                                       transform = vit_transforms,\n",
        "                                                                                       batch_size=32)\n",
        "len(train_dataloader_vit), len(test_dataloader_vit), class_names"
      ],
      "metadata": {
        "id": "XcmVyvRkt2Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Training ViT feature extractor\n"
      ],
      "metadata": {
        "id": "LqOJqSEOuJyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import engine\n",
        "\n",
        "# Setup optimizer\n",
        "optimizer = torch.optim.Adam(vit_model.parameters(), lr=1e-3)\n",
        "\n",
        "# Setup loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train ViT model\n",
        "set_seeds()\n",
        "vit_results = engine.train(model=vit_model,\n",
        "                           train_dataloader=train_dataloader_vit,\n",
        "                           test_dataloader=test_dataloader_vit,\n",
        "                           optimizer=optimizer,\n",
        "                           loss_fn=loss_fn,\n",
        "                           epochs=50,\n",
        "                           device=device)\n"
      ],
      "metadata": {
        "id": "rDIzsQg4wWjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 4.3 Inspecting ViT loss curves\n",
        "\n",
        "from helper_functions import plot_loss_curves\n",
        "plot_loss_curves(vit_results)"
      ],
      "metadata": {
        "id": "ZLrT08SPxzqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4 Saving ViT feature extractor\n"
      ],
      "metadata": {
        "id": "6fv9l3GzyVOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "from going_modular.going_modular import utils\n",
        "\n",
        "utils.save_model(model=vit_model,\n",
        "                 target_dir=\"models\",\n",
        "                 model_name=\"vit_feature_extractor_20_percent.pth\")"
      ],
      "metadata": {
        "id": "s4DDWmY3ycXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5 Checking the size of ViT feature extractor"
      ],
      "metadata": {
        "id": "xUILs_6SygeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Get the model size in bytes then convert to megabytes\n",
        "pretrained_model_path = Path(\"models/vit_feature_extractor_20_percent.pth\")\n",
        "pretrained_model_size_bytes = pretrained_model_path.stat().st_size\n",
        "pretrained_vit_model_size = pretrained_model_size_bytes / (1024 * 1024)\n",
        "\n",
        "print(f\"Model size: {pretrained_model_size_bytes} bytes\")\n",
        "print(f\"Model size: {pretrained_vit_model_size} megabytes\")\n",
        "#"
      ],
      "metadata": {
        "id": "qTzhWF6jymos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.6 Collecting ViT feature extractor stats\n"
      ],
      "metadata": {
        "id": "nmOQBga3y7Ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count number of parameters in ViT\n",
        "vit_total_params = sum([param.numel() for param in vit_model.parameters()])\n",
        "vit_total_params"
      ],
      "metadata": {
        "id": "I_M5TwLFzOd9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}